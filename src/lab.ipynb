{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "from datasets.colmap import Parser\n",
    "\n",
    "with open('rick.pkl', 'rb') as f:\n",
    "    inputs = pickle.load(f)\n",
    "\n",
    "\n",
    "# {\n",
    "#     \"depth\": depth,\n",
    "#     \"camera_id\": camera_id,\n",
    "#     \"image_name\": image_name,\n",
    "#     \"parser\": parser,\n",
    "# },\n",
    "\n",
    "depth: np.ndarray = inputs['depth']\n",
    "camera_id:str = inputs['camera_id']\n",
    "image_name:str = inputs['image_name']\n",
    "parser: Parser = inputs['parser']\n",
    "\n",
    "# TODO: GO OVER ALL OF THIS CUZ ALL OF IT IS PROBABLY WRONG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "depth_scalar=0.07240226110038772, np.std(depth_ratios)=0.040816114113786765\n"
     ]
    }
   ],
   "source": [
    "cam2world = parser.camtoworlds[camera_id]\n",
    "K = parser.Ks_dict[camera_id]\n",
    "imsize = parser.imsize_dict[camera_id]\n",
    "\n",
    "sfm_points = parser.points[parser.point_indices[image_name]]\n",
    "world2cam = np.linalg.inv(cam2world)\n",
    "P = K @ world2cam[:3]\n",
    "\n",
    "sfm_points_camera = P @ np.vstack([sfm_points.T, np.ones(sfm_points.shape[0])])\n",
    "sfm_points_camera = sfm_points_camera[:2] / sfm_points_camera[2]\n",
    "valid_sfm_pt_indices = np.logical_and(\n",
    "        np.logical_and(sfm_points_camera[0] >= 0, sfm_points_camera[0] < imsize[0]),\n",
    "        np.logical_and(sfm_points_camera[1] >= 0, sfm_points_camera[1] < imsize[1]),\n",
    "    )\n",
    "valid_sfm_pt_indices = np.logical_and(valid_sfm_pt_indices, sfm_points[:, 2] > 0)\n",
    "sfm_points_camera = sfm_points_camera[\n",
    "    :, valid_sfm_pt_indices\n",
    "]\n",
    "\n",
    "depth_ratios = sfm_points[valid_sfm_pt_indices, 2] / depth[sfm_points_camera[1].astype(int), sfm_points_camera[0].astype(int)]\n",
    "depth_scalar = np.mean(depth_ratios)\n",
    "print(f\"{depth_scalar=}, {np.std(depth_ratios)=}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1297, 840, 2)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mgrid[0 : imsize[1], 0 : imsize[0]].T.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "camera_grid = np.dstack(\n",
    "    [np.mgrid[0 : imsize[1], 0 : imsize[0]].T, depth.T * depth_scalar]\n",
    ")\n",
    "xyz = (np.linalg.inv(K) @ camera_grid.reshape(-1, 3).T).T\n",
    "\n",
    "xyz = cam2world @ np.vstack([xyz.T, np.ones(xyz.shape[0])])\n",
    "\n",
    "xyz = xyz[:3].reshape(imsize[1], imsize[0], 3)\n",
    "\n",
    "# xyz[2] = depth.reshape(-1)\n",
    "# xyz[:2] *= xyz[2]\n",
    "# xyz = np.vstack([xyz, np.ones(xyz.shape[1])])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn\n",
    "\n",
    "\n",
    "factors = xyz[np.round(sfm_points_camera[1]).astype(int), np.round(sfm_points_camera[0]).astype(int)] / sfm_points[valid_sfm_pt_indices]\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "gs_init_compare",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
