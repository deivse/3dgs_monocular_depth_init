{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "from datasets.colmap import Parser\n",
    "from scipy.ndimage import gaussian_filter\n",
    "\n",
    "with open(\"rick.pkl\", \"rb\") as f:\n",
    "    inputs = pickle.load(f)\n",
    "\n",
    "\n",
    "depth: np.ndarray = inputs[\"depth\"]\n",
    "camera_id: str = inputs[\"camera_id\"]\n",
    "image_name: str = inputs[\"image_name\"]\n",
    "parser: Parser = inputs[\"parser\"]\n",
    "\n",
    "\n",
    "def plot3d(xyz, color=\"b\", ax=None):\n",
    "    if ax is None:\n",
    "        fig = plt.figure()\n",
    "        ax = fig.add_subplot(111, projection=\"3d\")\n",
    "\n",
    "    coords = xyz.reshape(-1, 3)\n",
    "\n",
    "    ax.scatter(\n",
    "        coords[:, 0].flatten(),\n",
    "        coords[:, 1].flatten(),\n",
    "        coords[:, 2].flatten(),\n",
    "        s=1,\n",
    "        c=color,\n",
    "    )\n",
    "\n",
    "    ax.set_xlabel(\"X\")\n",
    "    ax.set_ylabel(\"Y\")\n",
    "    ax.set_zlabel(\"Z\")\n",
    "\n",
    "    ax.set_box_aspect([1, 1, 1])  # Aspect ratio is 1:1:1\n",
    "    ax.set_xlim([-5, 5])\n",
    "    ax.set_ylim([-5, 5])\n",
    "    ax.set_zlim([-5, 5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "np.sum(valid_sfm_pt_indices)=449 4953\n",
      "depth_scalar=0.28225370672094824, np.std(depth_ratios)=0.08666015217941038\n"
     ]
    }
   ],
   "source": [
    "cam2world = parser.camtoworlds[camera_id]\n",
    "K = parser.Ks_dict[camera_id]\n",
    "imsize = parser.imsize_dict[camera_id]\n",
    "\n",
    "sfm_points = parser.points[parser.point_indices[image_name]]\n",
    "\n",
    "# plot3d(sfm_points)\n",
    "\n",
    "R = cam2world[:3, :3].T\n",
    "C = -cam2world[:3, :3] @ cam2world[:3, 3]\n",
    "\n",
    "P = K @ R @ np.hstack([np.eye(3), -C[:, None]])\n",
    "\n",
    "sfm_points_camera = P @ np.vstack([sfm_points.T, np.ones(sfm_points.shape[0])])\n",
    "sfm_points_camera_homo = sfm_points_camera\n",
    "sfm_points_camera = sfm_points_camera[:2] / sfm_points_camera[2]\n",
    "\n",
    "valid_sfm_pt_indices = np.logical_and(\n",
    "    np.logical_and(sfm_points_camera[0] >= 0, sfm_points_camera[0] < imsize[0]),\n",
    "    np.logical_and(sfm_points_camera[1] >= 0, sfm_points_camera[1] < imsize[1]),\n",
    ")\n",
    "valid_sfm_pt_indices = np.logical_and(valid_sfm_pt_indices, sfm_points[:, 2] > 0)\n",
    "print(f\"{np.sum(valid_sfm_pt_indices)=}\", len(valid_sfm_pt_indices))\n",
    "sfm_points_camera = sfm_points_camera[:, valid_sfm_pt_indices]\n",
    "\n",
    "depth_ratios = sfm_points_camera_homo[2, valid_sfm_pt_indices] / (\n",
    "    1 + depth[sfm_points_camera[1].astype(int), sfm_points_camera[0].astype(int)]\n",
    ")\n",
    "depth_scalar = np.mean(depth_ratios)\n",
    "print(f\"{depth_scalar=}, {np.std(depth_ratios)=}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(840, 1297, 3)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "camera_grid = np.dstack(\n",
    "    [np.mgrid[0 : imsize[0], 0 : imsize[1]].T, depth_scalar * (1 + depth)]\n",
    ")\n",
    "# camera_grid[:, :, :2] *= parser.factor\n",
    "camera_grid[:, :, 0] = camera_grid[:, :, 0] * camera_grid[:, :, 2]\n",
    "camera_grid[:, :, 1] = camera_grid[:, :, 1] * camera_grid[:, :, 2]\n",
    "\n",
    "camera_grid.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib qt5\n",
    "\n",
    "def transform_camera_to_world_space(camera_homo, downsample_factor):\n",
    "    dense_world = np.linalg.inv(K) @ camera_homo.reshape((-1, 3)).T\n",
    "    dense_world = (cam2world @ np.vstack([dense_world, np.ones(dense_world.shape[1])]))[\n",
    "        :3\n",
    "    ].T\n",
    "    dense_world = dense_world.reshape((imsize[0], imsize[1], 3))\n",
    "    return dense_world[::downsample_factor, ::downsample_factor, :]\n",
    "\n",
    "\n",
    "xyz_full = transform_camera_to_world_space(camera_grid, 1)\n",
    "xyz = transform_camera_to_world_space(camera_grid,  10)\n",
    "camera_plane_xyz = transform_camera_to_world_space(\n",
    "    np.dstack([np.mgrid[0 : imsize[0], 0 : imsize[1]].T, np.ones(depth.shape)]),\n",
    "    10,\n",
    ")\n",
    "\n",
    "fig = plt.figure()\n",
    "ax = fig.add_subplot(111, projection=\"3d\")\n",
    "\n",
    "# Downsample xyz to include less points\n",
    "\n",
    "plot3d(sfm_points, \"r\", ax)\n",
    "plot3d(xyz.reshape(-1, 3), \"g\", ax)\n",
    "plot3d(\n",
    "    xyz_full[\n",
    "        np.round(sfm_points_camera[0]).astype(int),\n",
    "        np.round(sfm_points_camera[1]).astype(int),\n",
    "        :,\n",
    "    ],\n",
    "    \"y\",\n",
    "    ax,\n",
    ")\n",
    "plot3d(camera_plane_xyz, \"b\", ax)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-0.1725644 ,  0.60818781,  0.23968236])"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "camera_plane_xyz[imsize[0]//2, imsize[1]//2]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
