{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "from datasets.colmap import Parser\n",
    "from scipy.ndimage import gaussian_filter\n",
    "\n",
    "with open(\"rick.pkl\", \"rb\") as f:\n",
    "    inputs = pickle.load(f)\n",
    "\n",
    "\n",
    "depth: np.ndarray = inputs[\"depth\"]\n",
    "camera_id: str = inputs[\"camera_id\"]\n",
    "image_name: str = inputs[\"image_name\"]\n",
    "parser: Parser = inputs[\"parser\"]\n",
    "\n",
    "\n",
    "def plot3d(xyz, color=\"b\", ax=None):\n",
    "    if ax is None:\n",
    "        fig = plt.figure()\n",
    "        ax = fig.add_subplot(111, projection=\"3d\")\n",
    "\n",
    "    coords = xyz.reshape(-1, 3)\n",
    "\n",
    "    ax.scatter(\n",
    "        coords[:, 0].flatten(),\n",
    "        coords[:, 1].flatten(),\n",
    "        coords[:, 2].flatten(),\n",
    "        s=1,\n",
    "        c=color,\n",
    "    )\n",
    "\n",
    "    ax.set_xlabel(\"X\")\n",
    "    ax.set_ylabel(\"Y\")\n",
    "    ax.set_zlabel(\"Z\")\n",
    "\n",
    "    ax.set_box_aspect([1, 1, 1])  # Aspect ratio is 1:1:1\n",
    "    ax.set_xlim([-5, 5])\n",
    "    ax.set_ylim([-5, 5])\n",
    "    ax.set_zlim([-5, 5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib qt5\n",
    "\n",
    "\n",
    "cam2world = parser.camtoworlds[camera_id]\n",
    "K = parser.Ks_dict[camera_id]\n",
    "imsize = parser.imsize_dict[camera_id]\n",
    "w2c = np.linalg.inv(cam2world)\n",
    "R = w2c[:3, :3]\n",
    "C = -R.T @ w2c[:3, 3]\n",
    "P = K @ R @ np.hstack([np.eye(3), -C[:, None]])\n",
    "\n",
    "def transform_camera_to_world_space(camera_homo):\n",
    "    dense_world = np.linalg.inv(K) @ camera_homo.reshape((-1, 3)).T\n",
    "    dense_world = (\n",
    "        cam2world @ np.vstack([dense_world, np.ones(dense_world.shape[1])])\n",
    "    )[:3].T\n",
    "    return dense_world.reshape((-1, 3))\n",
    "\n",
    "\n",
    "some_3d_pts = np.array(\n",
    "    [\n",
    "        [1, 1, 1],\n",
    "        [1, 1, -1],\n",
    "        [1, -1, 1],\n",
    "        [-1, 1, 1],\n",
    "        [-1, -1, -1]\n",
    "    ]\n",
    ")\n",
    "\n",
    "projected_homo = P @ np.vstack([some_3d_pts.T, np.ones(some_3d_pts.shape[0])])\n",
    "\n",
    "\n",
    "projected_screen = projected_homo[:2] / projected_homo[2]\n",
    "\n",
    "assert np.allclose(some_3d_pts.astype(float), transform_camera_to_world_space(projected_homo.T))\n",
    "\n",
    "\n",
    "sfm_points = parser.points[parser.point_indices[image_name]]\n",
    "\n",
    "def get_depth_scalar():\n",
    "    sfm_points_camera_homo = P @ np.vstack(\n",
    "        [sfm_points.T, np.ones(sfm_points.shape[0])]\n",
    "    )\n",
    "    sfm_points_camera = sfm_points_camera_homo[:2] / sfm_points_camera_homo[2]\n",
    "\n",
    "    valid_sfm_pt_indices = np.logical_and(\n",
    "        np.logical_and(sfm_points_camera[0] >= 0, sfm_points_camera[0] < imsize[0]),\n",
    "        np.logical_and(sfm_points_camera[1] >= 0, sfm_points_camera[1] < imsize[1]),\n",
    "    )\n",
    "\n",
    "    if np.sum(valid_sfm_pt_indices) < 10:\n",
    "        return None, None\n",
    "\n",
    "    # TODO: beneficial?\n",
    "    # sfm_point_err = parser.points_err[parser.point_indices[image_name]]\n",
    "    # valid_sfm_pt_indices = np.logical_and(\n",
    "    #     valid_sfm_pt_indices, sfm_point_err < 1\n",
    "    # )\n",
    "\n",
    "    sfm_points_camera = sfm_points_camera[:, valid_sfm_pt_indices]\n",
    "    depth_ratios = sfm_points_camera_homo[2, valid_sfm_pt_indices] / (\n",
    "        1\n",
    "        + depth[sfm_points_camera[1].astype(int), sfm_points_camera[0].astype(int)]\n",
    "    )\n",
    "\n",
    "    depth_scalar = np.mean(depth_ratios)\n",
    "    # print(f\"{depth_scalar=}, {np.std(depth_ratios)=}\")\n",
    "    return depth_scalar, sfm_points_camera_homo\n",
    "\n",
    "depth_scalar, sfm_points_camera_homo = get_depth_scalar()\n",
    "if depth_scalar is None:\n",
    "    raise\n",
    "\n",
    "camera_grid_homo = np.dstack(\n",
    "    [np.mgrid[0 : imsize[0], 0 : imsize[1]].T, depth_scalar * (1 + depth)]\n",
    ")\n",
    "\n",
    "camera_grid_homo[:, :, 0] = (camera_grid_homo[:, :, 0] + 0.5) * camera_grid_homo[:, :, 2]\n",
    "camera_grid_homo[:, :, 1] = (camera_grid_homo[:, :, 1] + 0.5) * camera_grid_homo[:, :, 2]\n",
    "\n",
    "pts = transform_camera_to_world_space(camera_grid_homo)\n",
    "\n",
    "camera_plane_xyz = transform_camera_to_world_space(\n",
    "    np.array([[x, imsize[1], 1] for x in np.arange(0, imsize[0])])\n",
    ")\n",
    "\n",
    "\n",
    "fig = plt.figure()\n",
    "ax = fig.add_subplot(111, projection=\"3d\")\n",
    "# plot3d(parser.points[::10,], \"y\", ax)\n",
    "plot3d(sfm_points[::3, :], \"y\", ax)\n",
    "\n",
    "# tmp = sfm_points_camera_homo[0]\n",
    "# sfm_points_camera_homo[0] = sfm_points_camera_homo[1]\n",
    "# sfm_points_camera_homo[1] = tmp\n",
    "sfm_points_camera_homo = (\n",
    "    np.linalg.inv(K) @ sfm_points_camera_homo.T.reshape((-1, 3)).T\n",
    ")\n",
    "sfm_points_camera_homo = (\n",
    "    cam2world\n",
    "    @ np.vstack([sfm_points_camera_homo, np.ones(sfm_points_camera_homo.shape[1])])\n",
    ")[:3].T\n",
    "plot3d(sfm_points_camera_homo, \"r\", ax)\n",
    "# plot3d(pts.reshape(-1, 3)[::30, :], \"g\", ax)\n",
    "plot3d(camera_plane_xyz, \"b\", ax)\n",
    "plt.show(block=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "np.sum(valid_sfm_pt_indices)=449 4953\n",
      "depth_scalar=0.28225370672094824, np.std(depth_ratios)=0.08666015217941038\n"
     ]
    }
   ],
   "source": [
    "cam2world = parser.camtoworlds[camera_id]\n",
    "K = parser.Ks_dict[camera_id]\n",
    "imsize = parser.imsize_dict[camera_id]\n",
    "\n",
    "sfm_points = parser.points[parser.point_indices[image_name]]\n",
    "\n",
    "# plot3d(sfm_points)\n",
    "\n",
    "R = cam2world[:3, :3].T\n",
    "C = -cam2world[:3, :3] @ cam2world[:3, 3]\n",
    "\n",
    "P = K @ R @ np.hstack([np.eye(3), -C[:, None]])\n",
    "\n",
    "sfm_points_camera = P @ np.vstack([sfm_points.T, np.ones(sfm_points.shape[0])])\n",
    "sfm_points_camera_homo = sfm_points_camera\n",
    "sfm_points_camera = sfm_points_camera[:2] / sfm_points_camera[2]\n",
    "\n",
    "valid_sfm_pt_indices = np.logical_and(\n",
    "    np.logical_and(sfm_points_camera[0] >= 0, sfm_points_camera[0] < imsize[0]),\n",
    "    np.logical_and(sfm_points_camera[1] >= 0, sfm_points_camera[1] < imsize[1]),\n",
    ")\n",
    "valid_sfm_pt_indices = np.logical_and(valid_sfm_pt_indices, sfm_points[:, 2] > 0)\n",
    "print(f\"{np.sum(valid_sfm_pt_indices)=}\", len(valid_sfm_pt_indices))\n",
    "sfm_points_camera = sfm_points_camera[:, valid_sfm_pt_indices]\n",
    "\n",
    "depth_ratios = sfm_points_camera_homo[2, valid_sfm_pt_indices] / (\n",
    "    1 + depth[sfm_points_camera[1].astype(int), sfm_points_camera[0].astype(int)]\n",
    ")\n",
    "depth_scalar = np.mean(depth_ratios)\n",
    "print(f\"{depth_scalar=}, {np.std(depth_ratios)=}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(840, 1297, 3)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "camera_grid = np.dstack(\n",
    "    [np.mgrid[0 : imsize[0], 0 : imsize[1]].T, depth_scalar * (1 + depth)]\n",
    ")\n",
    "# camera_grid[:, :, :2] *= parser.factor\n",
    "camera_grid[:, :, 0] = camera_grid[:, :, 0] * camera_grid[:, :, 2]\n",
    "camera_grid[:, :, 1] = camera_grid[:, :, 1] * camera_grid[:, :, 2]\n",
    "\n",
    "camera_grid.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib qt5\n",
    "\n",
    "def transform_camera_to_world_space(camera_homo, downsample_factor):\n",
    "    dense_world = np.linalg.inv(K) @ camera_homo.reshape((-1, 3)).T\n",
    "    dense_world = (cam2world @ np.vstack([dense_world, np.ones(dense_world.shape[1])]))[\n",
    "        :3\n",
    "    ].T\n",
    "    dense_world = dense_world.reshape((imsize[0], imsize[1], 3))\n",
    "    return dense_world[::downsample_factor, ::downsample_factor, :]\n",
    "\n",
    "\n",
    "xyz_full = transform_camera_to_world_space(camera_grid, 1)\n",
    "xyz = transform_camera_to_world_space(camera_grid,  10)\n",
    "camera_plane_xyz = transform_camera_to_world_space(\n",
    "    np.dstack([np.mgrid[0 : imsize[0], 0 : imsize[1]].T, np.ones(depth.shape)]),\n",
    "    10,\n",
    ")\n",
    "\n",
    "fig = plt.figure()\n",
    "ax = fig.add_subplot(111, projection=\"3d\")\n",
    "\n",
    "# Downsample xyz to include less points\n",
    "\n",
    "plot3d(sfm_points, \"r\", ax)\n",
    "plot3d(xyz.reshape(-1, 3), \"g\", ax)\n",
    "plot3d(\n",
    "    xyz_full[\n",
    "        np.round(sfm_points_camera[0]).astype(int),\n",
    "        np.round(sfm_points_camera[1]).astype(int),\n",
    "        :,\n",
    "    ],\n",
    "    \"y\",\n",
    "    ax,\n",
    ")\n",
    "plot3d(camera_plane_xyz, \"b\", ax)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-0.1725644 ,  0.60818781,  0.23968236])"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "camera_plane_xyz[imsize[0]//2, imsize[1]//2]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "gs_init_compare",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
